# helper functions for everything else

import os
import numpy as np
import copy
import skimage.morphology as morph
import skimage.measure
import pandas as pd
import xarray as xr


# data loading

def load_tifs_from_points_dir(point_dir, tif_folder, tifs=None):
    """Takes a set of TIFs from a directory structure organised by points, and loads them into a numpy array.

        Args:
            point_dir: string to directory of points
            tif_folder: name of tif_folder within each point
            tifs: optional list of TIFs to load, otherwise loads all TIFs

        Returns:
            Numpy array with shape [num_dir, num_tifs, x_dim, y_dim]
    """

    if not os.path.isdir(point_dir):
        raise ValueError("Directory does not exist")

    # get all point folders
    points = os.listdir(point_dir)
    points = [point for point in points if 'Point' in point]

    if len(points) == 0:
        raise ValueError("No points found in directory")

    if not os.path.isdir(os.path.join(point_dir, points[0], tif_folder)):
        raise ValueError("Invalid tif folder name")

    # get tifs from first point directory if no tif names supplied
    if tifs is None:
        tifs = os.listdir(os.path.join(point_dir, points[0], tif_folder))
        tifs = [tif for tif in tifs if '.tif' in tif]

    if len(tifs) == 0:
        raise ValueError("No tifs found in designated folder")

    for tif in tifs:
        if not os.path.isfile(os.path.join(point_dir, points[0], tif_folder, tif)):
            print(os.path.join(point_dir, points[0], tif_folder, tif))
            raise ValueError("Could not find {} in supplied directory".format(tif))

    test_img = io.imread(os.path.join(point_dir, points[0], tif_folder, tifs[0]))
    img_data = np.zeros((len(points), len(tifs), test_img.shape[0], test_img.shape[1]))

    for point in range(len(points)):
        for tif in range(len(tifs)):
            img_data[point, tif, :, :] = io.imread(os.path.join(point_dir, points[point], tif_folder, tifs[tif]))

    img_xr = xr.DataArray(img_data, coords=[points, tifs, range(test_img.shape[0]), range(test_img.shape[0])],
                          dims=["point_folder", "channel", "x_axis", "y_axis"])

    return img_xr




# plotting functions


def randomize_labels(label_map):
    """Takes in a labeled matrix and swaps the integers around so that color gradient has better contrast

    Inputs:
    label_map(2D numpy array): labeled TIF with each object assigned a unique value

    Outputs:
    swapped_map(2D numpy array): labeled TIF with object labels permuted"""

    max_val = np.max(label_map)
    for cell_target in range(1, max_val):
        swap_1 = cell_target
        swap_2 = np.random.randint(1, max_val)
        swap_1_mask = label_map == swap_1
        swap_2_mask = label_map == swap_2
        label_map[swap_1_mask] = swap_2
        label_map[swap_2_mask] = swap_1

    label_map = label_map.astype('int16')

    return label_map


def outline_objects(L_matrix, list_of_lists):
    """takes in an L matrix generated by skimage.label, along with a list of lists, and returns a mask that has the
    pixels for all cells from each list represented as integer values for easy plotting"""

    L_plot = copy.deepcopy(L_matrix).astype(float)

    for idx, val in enumerate(list_of_lists):
        mask = np.isin(L_plot, val)

        # use a negative value to not interfere with cell labels
        L_plot[mask] = -(idx + 2)

    L_plot[L_plot > 1] = 1
    L_plot = np.absolute(L_plot)
    L_plot = L_plot.astype('int16')
    return L_plot


# training data generation
def process_training_data(interior_contour, interior_border_contour):
    """Take in a contoured map of the border of each cell as well as entire cell, and generate annotated label map
    where each cell is its own unique pixel value

    Args:
        interior_contour: TIF with interior pixels as 1s, all else as 0
        interior_border_contour: TIF with all cellular pixels as 1s, all else as 0s

    Returns:
        label_contour: np.array with pixels belonging to each cell as a unique integer"""

    if np.sum(interior_contour) == 0:
        raise ValueError("Border contour is empty array")

    if np.sum(interior_border_contour) == 0:
        raise ValueError("Cell contour is empty array")

    if np.sum(interior_contour) > np.sum(interior_border_contour):
        raise ValueError("Arguments are likely switched, interior_contour is larger than interior_border_contour")

    # label cells
    interior_contour = skimage.measure.label(interior_contour, connectivity=1)

    # for each individual cell, expand to slightly larger than original size one pixel at a time
    new_masks = copy.copy(interior_contour)
    for idx in range(2):
        for cell_label in np.unique(new_masks)[1:]:
            img = new_masks == cell_label
            img = morph.binary_dilation(img, morph.disk(1))
            new_masks[img] = cell_label

    # set pixels to 0 anywhere outside bounds of original shape
    label_contour = randomize_labels(new_masks.astype("int"))
    label_contour[interior_border_contour == 0] = 0

    missed_pixels = np.sum(np.logical_and(interior_border_contour > 0, label_contour < 1))
    print("Erosion and dilating resulted in a total of {} pixels "
          "that are no longer marked out of {}".format(missed_pixels, interior_contour.shape[0] ** 2))

    return label_contour

# accuracy evaluation


def compare_contours(predicted_label, contour_label):

    """Compares two distinct segmentation outputs

    Args:
        predicted_label: label map generated by algorithm
        contour_label: label map generated from ground truth data

    Returns:
        cell_frame: a pandas dataframe containing metrics for each cell in ground truth data"""

    # check to see if data has been supplied with labels already, or needs to be labeled
    if len(np.unique(predicted_label)) < 3:
        predicted_label = skimage.measure.label(predicted_label, connectivity=1)

    if len(np.unique(contour_label)) < 3:
        contour_label = skimage.measure.label(contour_label, connectivity=1)

    # get region props of predicted cells and initialize datastructure for storing values
    cell_frame = pd.DataFrame(columns=["contour_cell", "contour_cell_size", "predicted_cell", "predicted_cell_size",
                                       "percent_overlap", "merged", "split", "missing", "low_quality", "created"])

    # loop through each contoured cell, and compute accuracy metrics for overlapping predicting cells
    for contour_cell in range(1, np.max(contour_label) + 1):
        # generate a mask for the contoured cell, get all predicted cells that overlap the mask
        mask = contour_label == contour_cell
        overlap_id, overlap_count = np.unique(predicted_label[mask], return_counts=True)
        overlap_id, overlap_count = np.array(overlap_id), np.array(overlap_count)

        # remove cells that aren't at least 5% of current cell
        contour_cell_size = np.sum(mask)
        idx = overlap_count > 0.05 * contour_cell_size
        overlap_id, overlap_count = overlap_id[idx], overlap_count[idx]

        # sort the overlap counts in decreasing order
        sort_idx = np.argsort(-overlap_count)
        overlap_id, overlap_count = overlap_id[sort_idx], overlap_count[sort_idx]

        # check and see if maps primarily to background
        if overlap_id[0] == 0:
            if overlap_count[0] / contour_cell_size > 0.8:
                # more than 80% of cell is overlapping with background, classify predicted cell as missing
                cell_frame = cell_frame.append({"contour_cell": contour_cell, "contour_cell_size": contour_cell_size,
                                                "predicted_cell": 0, "predicted_cell_size": 0,
                                                "percent_overlap": overlap_count[0] / contour_cell_size, "merged": False,
                                                "split": False, "missing": True, "low_quality": False,
                                                "created": False}, ignore_index=True)
                continue
            else:
                # not missing, just bad segmentation. Classify predicted cell as bad
                # TODO: figure out how often this condition is true, what do we do with remaining overlap targets
                cell_frame = cell_frame.append(
                    {"contour_cell": contour_cell, "contour_cell_size": contour_cell_size,
                     "predicted_cell": overlap_id[1], "predicted_cell_size": np.sum(predicted_label == overlap_id[1]),
                     "percent_overlap": overlap_count[0] / contour_cell_size, "merged": False,
                     "split": False, "missing": False, "low_quality": True, "created": False}, ignore_index=True)
                continue
        else:
            # remove background as target cell and change cell size to for calculation
            if 0 in overlap_id:
                keep_idx = overlap_id != 0
                contour_cell_size -= overlap_count[~keep_idx][0]
                overlap_id, overlap_count = overlap_id[keep_idx], overlap_count[keep_idx]

        # go through logic to determine relationship between overlapping cells
        if overlap_count[0] / contour_cell_size > 0.9:

            # if greater than 90% of pixels contained in first overlap, assign to that cell
            pred_cell = overlap_id[0]
            pred_cell_size = np.sum(predicted_label == pred_cell)
            percnt = overlap_count[0] / contour_cell_size

            cell_frame = cell_frame.append({"contour_cell": contour_cell, "contour_cell_size": contour_cell_size,
                                            "predicted_cell": pred_cell, "predicted_cell_size": pred_cell_size,
                                            "percent_overlap": percnt, "merged": False, "split": False,
                                            "missing": False, "low_quality": False, "created": False}, ignore_index=True)
        else:
            # No single predicted cell occupies more than 90% of contour cell size, figure out the type of error made
            split_flag = False
            bad_flag = False
            # TODO check if first cell also has at least 80% of volume contained in contour cell?
            # TODO can keep a counter of number of cells that meet this criteria, if >2 then split?
            for cell in range(1, len(overlap_id)):
                pred_cell_size = np.sum(predicted_label == overlap_id[cell])
                percnt = overlap_count[cell] / contour_cell_size
                if overlap_count[cell] / pred_cell_size > 0.7:
                    # multiple predicted cells were assigned to single target cell, hence split
                    split_flag = True
                    cell_frame = cell_frame.append(
                        {"contour_cell": contour_cell, "contour_cell_size": contour_cell_size,
                         "predicted_cell": overlap_id[cell], "predicted_cell_size": pred_cell_size,
                         "percent_overlap": percnt, "merged": False, "split": True,
                         "missing": False, "low_quality": False, "created": False}, ignore_index=True)
                else:
                    # this cell hasn't been split, just poorly assigned
                    bad_flag = True
                    cell_frame = cell_frame.append(
                        {"contour_cell": contour_cell, "contour_cell_size": contour_cell_size,
                         "predicted_cell": overlap_id[cell], "predicted_cell_size": pred_cell_size,
                         "percent_overlap": percnt, "merged": False, "split": False,
                         "missing": False, "low_quality": True, "created": False}, ignore_index=True)

            # assign the first cell, based on whether or not subsequent cells indicate split or bad
            if bad_flag and split_flag:
                bad_flag = False
            cell_frame = cell_frame.append({"contour_cell": contour_cell, "contour_cell_size": contour_cell_size,
                                            "predicted_cell": overlap_id[0], "predicted_cell_size": overlap_count[0],
                                            "percent_overlap": overlap_count[0] / contour_cell_size, "merged": False,
                                            "split": split_flag, "missing": False, "low_quality": bad_flag,
                                            "created": False}, ignore_index=True)

    # check and see if any new cells were created in predicted_label that don't exist in contour_label
    for predicted_cell in range(1, np.max(predicted_label) + 1):
        if not np.isin(predicted_cell, cell_frame["predicted_cell"]):
            cell_frame = cell_frame.append({"contour_cell": 0, "contour_cell_size": 0, "predicted_cell": predicted_cell,
                                            "predicted_cell_size": np.sum(predicted_label == predicted_cell),
                                            "percent_overlap": 0, "merged": False, "split": split_flag,
                                            "missing": False, "low_quality": False, "created": True}, ignore_index=True)

    return cell_frame, predicted_label, contour_label

# DSB-score adapated from https://www.biorxiv.org/content/10.1101/580605v1.full
# object IoU matrix adapted from code written by Morgan Schwartz

def calc_iou_matrix(ground_truth_label, predicted_label):
    """Calculates pairwise ious between all cells from two masks

    Args:
        ground_truth_label: 2D label array representing ground truth contours
        predicted_label: 2D labeled array representing predicted contours

    Returns:
        iou_matrix: matrix of ground_truth x predicted cells with iou value for each
    """

    if len(np.unique(ground_truth_label)) < 3:
        raise ValueError("Ground truth array was not pre-labeled")

    if len(np.unique(predicted_label)) < 3:
        raise ValueError("Predicted array was not pre-labeled")

    iou_matrix = np.zeros((np.max(ground_truth_label), np.max(predicted_label)))

    for i in range(1, iou_matrix.shape[0] + 1):
        gt_img = ground_truth_label == i
        overlaps = np.unique(predicted_label[gt_img])
        for j in overlaps:
            pd_img = predicted_label == j
            intersect = np.sum(np.logical_and(gt_img, pd_img))
            union = np.sum(np.logical_or(gt_img, pd_img))
            # adjust index by one to account for not including background
            iou_matrix[i - 1, j - 1] = intersect / union
    return iou_matrix


def calc_modified_average_precision(iou_matrix, thresholds):
    """Calculates the average precision between two masks across a range of iou thresholds

    Args:
        iou_matrix: intersection over union matrix
        thresholds: list used to threshold iou values in matrix

    Returns:
        scores: list of modified average precision values for each threshold
        false_neg_idx: array of booleans indicating whether cell was flagged as false positive at each threshold
        false_pos_idx: array of booleans indicating whether cell was flagged as false negative at each threshold"""

    if np.max(iou_matrix) > 1:
        raise ValueError("Improperly formatted iou_matrix, contains values greater than 1")

    if len(thresholds) == 0:
        raise ValueError("Must supply at least one threshold value")

    if np.any(np.logical_or(thresholds > 1, thresholds < 0)):
        raise ValueError("Thresholds must be between 0 and 1")

    scores = []
    false_neg_idx = np.zeros((len(thresholds), iou_matrix.shape[0]))
    false_pos_idx = np.zeros((len(thresholds), iou_matrix.shape[1]))

    for i in range(len(thresholds)):

        # threshold iou_matrix as designated value
        iou_matrix_thresh = iou_matrix > thresholds[i]

        # Calculate values based on projecting along prediction axis
        pred_proj = iou_matrix_thresh.sum(axis=1)

        # Zeros (aka absence of hits) correspond to true cells missed by prediction
        false_neg = pred_proj == 0
        false_neg_idx[i, :] = false_neg
        false_neg = np.sum(false_neg)

        # Calculate values based on projecting along truth axis
        truth_proj = iou_matrix_thresh.sum(axis=0)

        # Empty hits indicate predicted cells that do not exist in true cells
        false_pos = truth_proj == 0
        false_pos_idx[i, :] = false_pos
        false_pos = np.sum(false_pos)

        # Ones are true positives
        true_pos = np.sum(pred_proj == 1)

        score = true_pos / (true_pos + false_pos + false_neg)
        scores.append(score)
    return scores, false_neg_idx, false_pos_idx